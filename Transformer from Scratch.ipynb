{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28957f88",
   "metadata": {},
   "source": [
    "## Import the needed libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae956799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Deal with the dataframe\n",
    "import torch # Deal with neural network and tensors\n",
    "import numpy as np # Deal with the Matrixies and arrays\n",
    "import string # To Deal with the String object +]\n",
    "import re # Regular expressions library to deal with pattern matching and string manipulation. \n",
    "import contractions # Library have most of the contractions \n",
    "import nltk # The main library to deal with NLP problems\n",
    "from nltk.corpus import stopwords # To deal with stop words (contains list of stop words)\n",
    "from nltk.tokenize import word_tokenize # To tokenize the sentences\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim # To regonize the optimizer\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import dataset\n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence # Deal with the padding \n",
    "from sklearn.model_selection import train_test_split # To split data to test and training\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93dc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df= pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d4c8a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2c2aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3427ca9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that all the col not equal 0\n",
    "df[\"threat\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c468decf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that all the col not equal 0\n",
    "df[\"identity_hate\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb14fb",
   "metadata": {},
   "source": [
    "Deal with unbalnced data by getting a part of it which nearly balnced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd9edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15294\n"
     ]
    }
   ],
   "source": [
    "# Sum any record have 1 as in any class \n",
    "x = sum(df['toxic'] == 1)\n",
    "print(x)\n",
    "# Put any record that have all the 6 classes = 0 (true or false dataframe)\n",
    "zeroes= (df[\"toxic\"] == 0) & (df[\"severe_toxic\"] == 0) & (df[\"obscene\"] == 0) & (df[\"threat\"] == 0) & (df[\"insult\"] == 0) & (df[\"identity_hate\"] == 0)\n",
    "# Take the data that are not oll zeroes \n",
    "data_no_zero = df[np.logical_not(zeroes)]\n",
    "#This will make the data more balanced by take the data that have one in its record and put some zeroes record as a weight for the zeroes in each class \n",
    "df = pd.concat([data_no_zero, df[zeroes].sample(n=5000, random_state=42)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab4489",
   "metadata": {},
   "source": [
    "## Cleaning Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "477c4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the english stop words in a list\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7137b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_1st_step(record): # Function that hold the most basics cleaning functions\n",
    "    # .lower() function ---> change all the chars into lower case \n",
    "    record = record.lower()\n",
    "    \n",
    "    # re (object from the library).sub() help to find the specific pattern we give it in each element and replacet with '' (nothing)  \n",
    "    record = re.sub(r'https?://\\S+', '',record )\n",
    "    \n",
    "    # library (contractions) .fix() function to change all the contractions to there expansion\n",
    "    record = contractions.fix(record)\n",
    "    \n",
    "    # Delete with the punctuation\n",
    "    record = record.translate(str.maketrans('', '',  string.punctuation))\n",
    "    \n",
    "    # Delete any additional space (more than one space)\n",
    "    record = \" \".join(record.split())\n",
    "    \n",
    "#     # Remove the stop word \n",
    "#     record = record.apply(lambda x: ' '.join([word for word in x.split() if word not in (stopWords)])\n",
    "    # return the parameter after done all the above functions.\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd55d672",
   "metadata": {},
   "source": [
    "# The classes to built it from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075f09f",
   "metadata": {},
   "source": [
    "## Multi-Head-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ba34ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    # Give the constructor the dim of the model and the number of the head of the attention \n",
    "    def __init__(self, dim_model, no_heads):\n",
    "        # Call the constructor of the super MultiHeadAttentionb class \n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        # Check if the dim of the model divisible by the munber of the heads if yes do nothing but if no then send this \n",
    "        # sentence as an error\n",
    "        # assert is a python keyword to get true or false result if true will continue the excution if false will send warning  \n",
    "        assert dim_model % no_heads == 0, \"dim of the model should be divisible by the number of the heads\"\n",
    "        \n",
    "        # Declare the the dimention of the models\n",
    "        self.dim_model = dim_model\n",
    "        # Declare the number of the heads of the attention \n",
    "        self.no_heads = no_heads\n",
    "        # floor division from divide the size of the model and the number of the heads\n",
    "        self.d_k = dim_model // no_heads\n",
    "        \n",
    "        # Set square tensors with dims (dim of the model, dim of the model)\n",
    "        # nn.linear(input to layer, output from layer) to build a netwaork layer \n",
    "        self.tensor_q = nn.Linear(dim_model, dim_model) # query layer\n",
    "        self.tensor_k = nn.Linear(dim_model, dim_model) # key layer\n",
    "        self.tensor_v = nn.Linear(dim_model, dim_model) # value layer\n",
    "        self.tensor_output = nn.Linear(dim_model, dim_model) # the output layer\n",
    "     \n",
    "    # the Function to calculate the attention take (Q query , K key , v value and non mask)\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # torch.matmul() --> function to multiple the tensors \n",
    "        # (Query , the transpose of the key / square root of the d_k )\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None: # check if there is mask not equal none\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9) # fill the mask which = 0 and fill it with -1e9\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1) # apply the softmax function \n",
    "        result = torch.matmul(attn_probs, V) # Multiply the softmax output and the value tensor \n",
    "        return result # return the output of the function \n",
    "     \n",
    "    # function data to number of the heads \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, dim_model = x.size()\n",
    "        #viwe() --> Function to change the the dim but keep the same informations \n",
    "        return x.view(batch_size, seq_length, self.no_heads, self.d_k).transpose(1, 2) # transpose(dim1,dim2)\n",
    "    \n",
    "    # start to combine the output from each head in this function.\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        # contigous() Help to compine the heads \n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.dim_model)\n",
    "    \n",
    "    # forward() function to call split_heads function to split the (query, key , value) to the heads then call \n",
    "    # scaled_dot_product_attention() function to apply the attention on it \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.tensor_q(Q))\n",
    "        K = self.split_heads(self.tensor_k(K))\n",
    "        V = self.split_heads(self.tensor_v(V))\n",
    "        \n",
    "        # start the attention calculations \n",
    "        attention_result = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        # call the combine_heads() function to combine the attention that happen in each head and \n",
    "        # .tensor_output() --> function to help in further combination\n",
    "        output = self.tensor_output(self.combine_heads(attention_result))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f383c",
   "metadata": {},
   "source": [
    "## Position wise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87d663b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, dim_model, d_ff):\n",
    "        # Call the constructor from the super PositionWiseFeedForward class  \n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.layer1 = nn.Linear(dim_model, d_ff) \n",
    "        self.layer2 = nn.Linear(d_ff, dim_model)\n",
    "        self.relu = nn.ReLU() # Activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Give x (the input) to 1st layer then give it to the activation function then pass it into the 2 layer and \n",
    "        # pass it as the output of the function\n",
    "        return self.layer2(self.relu(self.layer1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc2a1df",
   "metadata": {},
   "source": [
    "## Positional encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c855e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, max_tokens_length):\n",
    "        # called the constructor from the super PositionalEncoding class \n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        # Creat a tensor with dims (the max number of the unique tokens , size of the model)\n",
    "        pe = torch.zeros(max_tokens_length, dim_model)\n",
    "        # arrange the tensor and increase the flexibility to take diffrent size input\n",
    "        position = torch.arange(0, max_tokens_length, dtype=torch.float).unsqueeze(1) \n",
    "        # 2nd part of the rule\n",
    "        div_term = torch.exp(torch.arange(0, dim_model, 2).float() * -(math.log(10000.0) / dim_model))\n",
    "        # sin(even postion * 2nd part of the rule)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # cos(odd positions * 2nd part of the rule)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # Buffer are tonsor that pass with the model (while saving and laoding the model)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # function return the input + the positional encoder \n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19831d71",
   "metadata": {},
   "source": [
    "## Encoder Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d143825",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, dim_model, num_heads, dim_ff, dropout):\n",
    "        # Call the constructor from the super EncoderLayer class \n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # Take an object from the MultiHeadAttention() class \n",
    "        self.multi_attention = MultiHeadAttention(dim_model, num_heads)\n",
    "        # Take an object from the PositionWiseFeedForward() class \n",
    "        self.feed_forward = PositionWiseFeedForward(dim_model, dim_ff)\n",
    "        # Create 2 normalization layers \n",
    "        self.normal1 = nn.LayerNorm(dim_model)\n",
    "        self.normal2 = nn.LayerNorm(dim_model)\n",
    "        # Create a dropout layer to prevent the overfitting\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask): # Build the encoder \n",
    "        # Start 1st step in the encodeing which is Calculate the attention\n",
    "        attn_output = self.multi_attention(x, x, x, mask)\n",
    "        # Then Normalize the output from the attention layer \n",
    "        x = self.normal1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Then 2nd step we claculate the feed forward from the input \n",
    "        ff_output = self.feed_forward(x)\n",
    "        # Then Normalize again and the step of the normalization should be repeated after each step\n",
    "        x = self.normal2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b70d29",
   "metadata": {},
   "source": [
    "## Decoder Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ad2d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, dim_model, no_heads, dim_ff, dropout):\n",
    "        # Call the constructor from super DecoderLayer() class \n",
    "        super(DecoderLayer, self).__init__()\n",
    "        # Create object from the MultiHeadAttention() class \n",
    "        self.self_attention  = MultiHeadAttention(dim_model, no_heads)\n",
    "        # Create another object from the MultiHeadAttention() class for the cross step between the outPut from the \n",
    "        # encoder and the multi-head attention in the decoder \n",
    "        self.cross_attention  = MultiHeadAttention(dim_model, no_heads)\n",
    "        # Create an object from the PositionWiseFeedForward() class \n",
    "        self.feed_forward = PositionWiseFeedForward(dim_model, dim_ff)\n",
    "        # Creat 3 layers of normalization layer same number as number of the steps in the decoder process\n",
    "        self.normal1 = nn.LayerNorm(dim_model)\n",
    "        self.normal2 = nn.LayerNorm(dim_model)\n",
    "        self.normal3 = nn.LayerNorm(dim_model)\n",
    "        # Create a dropout layer to prevent the overfitting by reducing co-adaptation between the units of the model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, encoder_output, src_mask, target_mask): # Build the decoder \n",
    "        # 1st step --> start to calculate the Attention and the masking\n",
    "        attention_output = self.self_attention(x, x, x, target_mask)\n",
    "        # then Normalize the output \n",
    "        x = self.normal1(x + self.dropout(attention_output))\n",
    "        # 2nd step --> Start to do the attention process on the encoder output and the output from the Multi-head \n",
    "        # attention in the decoder (1st step in the decoder) \n",
    "        attention_output = self.cross_attention (x, encoder_output, encoder_output, src_mask)\n",
    "        # Then normalize again\n",
    "        x = self.normal2(x + self.dropout(attention_output))\n",
    "        # 3rd step Calculate the feed forward \n",
    "        ff_output = self.feed_forward(x)\n",
    "        # Last Normalize again\n",
    "        x = self.normal3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91501314",
   "metadata": {},
   "source": [
    "## Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c484c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_unique_tokens_size, target_unique_tokens_size, dim_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        # Start to embedding the source and the target \n",
    "        # nn.embedding () --> function take (the number of the unique tokens , the dim of the embedding vector)\n",
    "        self.encoder_embedding = nn.Embedding(src_unique_tokens_size, dim_model)\n",
    "        self.decoder_embedding = nn.Embedding(target_unique_tokens_size, dim_model)\n",
    "        # Create an object from the PositionalEncoding() class and give it the model dim and the max number of tokens \n",
    "        self.positional_encoding = PositionalEncoding(dim_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(dim_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(dim_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(dim_model, target_unique_tokens_size)\n",
    "        # Relu--> \n",
    "        # 2nd linear layer----> output\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # Masking \n",
    "    def generate_mask(self, src, target):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        target_mask = (target != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = target.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        nopeak_mask = nopeak_mask.to(torch.device('cuda'))\n",
    "        target_mask = target_mask & nopeak_mask\n",
    "        return src_mask, target_mask\n",
    "\n",
    "    \n",
    "    def forward(self, src, target):\n",
    "        src_mask, target_mask = self.generate_mask(src, target)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        target_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(target)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = target_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, target_mask)\n",
    "        \n",
    "        output = self.fc(dec_output) #\n",
    "        # output self.fc2(output) # 2nd layer \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b7bbd2",
   "metadata": {},
   "source": [
    "### Start with Masking then embeding the data that will go in calc in the positional encoder \n",
    "### After that we do the encoder layer ( multi attention and Feed forward) \n",
    "### Take the output from the encoder layer to the decoder layer and make a cross attention and the feed forward "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197b6d58",
   "metadata": {},
   "source": [
    "## Start to split the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b01afe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "6       1             1        1       0       1              0\n",
       "12      1             0        0       0       0              0\n",
       "16      1             0        0       0       0              0\n",
       "42      1             0        1       0       1              1\n",
       "43      1             0        1       0       1              0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target= df.iloc[:, 2:8]\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e88d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into (tarin,test) and each to (src,target)\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['comment_text'] , target , test_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f65e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the train col into dataframe to have a col name \n",
    "train_x =  x_train.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "597161ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58787</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71909</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78991</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128843</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150971</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96455</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105991</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26586</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4245 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "58787       1             1        1       0       1              0\n",
       "415         1             0        1       0       1              0\n",
       "71909       1             0        1       0       1              0\n",
       "78991       1             0        1       0       1              0\n",
       "45237       0             0        0       0       0              0\n",
       "...       ...           ...      ...     ...     ...            ...\n",
       "128843      1             0        0       0       0              0\n",
       "150971      0             0        0       0       0              0\n",
       "96455       1             0        0       0       0              0\n",
       "105991      1             0        0       0       0              0\n",
       "26586       1             0        0       0       0              0\n",
       "\n",
       "[4245 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50ea9fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58787</th>\n",
       "      <td>Fuck, Shit, Damn, Cock, Pissant, Motherfucker,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Thank you for your RACIST experimenting with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71909</th>\n",
       "      <td>Don't be a Dick\\nYou know what you did, don't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78991</th>\n",
       "      <td>STOP CHANGON IT \\n\\nOR I AM TWIST OFF YOURE LI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45237</th>\n",
       "      <td>\"\\n\\n Nonexistent Image in \"\"Name\"\" \\n\\nThe im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128843</th>\n",
       "      <td>WHY DID YOU EDIT THE ARTICLE ON KURDISTAN? \\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150971</th>\n",
       "      <td>\"\\nAww thanks -) from PC 28 at Stevenage libra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96455</th>\n",
       "      <td>\":: I don't really want to deal with an amoeba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105991</th>\n",
       "      <td>AVRUCH you truly do show your colours.....this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26586</th>\n",
       "      <td>\"\\n Nissim Cahn vandals \\n\\nI've blocked them ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4245 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text\n",
       "58787   Fuck, Shit, Damn, Cock, Pissant, Motherfucker,...\n",
       "415     Thank you for your RACIST experimenting with t...\n",
       "71909   Don't be a Dick\\nYou know what you did, don't ...\n",
       "78991   STOP CHANGON IT \\n\\nOR I AM TWIST OFF YOURE LI...\n",
       "45237   \"\\n\\n Nonexistent Image in \"\"Name\"\" \\n\\nThe im...\n",
       "...                                                   ...\n",
       "128843  WHY DID YOU EDIT THE ARTICLE ON KURDISTAN? \\n\\...\n",
       "150971  \"\\nAww thanks -) from PC 28 at Stevenage libra...\n",
       "96455   \":: I don't really want to deal with an amoeba...\n",
       "105991  AVRUCH you truly do show your colours.....this...\n",
       "26586   \"\\n Nissim Cahn vandals \\n\\nI've blocked them ...\n",
       "\n",
       "[4245 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54d98ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then concat the the src and target of the training \n",
    "train_data = pd.concat([train_x , y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aec68894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58787</th>\n",
       "      <td>Fuck, Shit, Damn, Cock, Pissant, Motherfucker,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Thank you for your RACIST experimenting with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71909</th>\n",
       "      <td>Don't be a Dick\\nYou know what you did, don't ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78991</th>\n",
       "      <td>STOP CHANGON IT \\n\\nOR I AM TWIST OFF YOURE LI...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45237</th>\n",
       "      <td>\"\\n\\n Nonexistent Image in \"\"Name\"\" \\n\\nThe im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128843</th>\n",
       "      <td>WHY DID YOU EDIT THE ARTICLE ON KURDISTAN? \\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150971</th>\n",
       "      <td>\"\\nAww thanks -) from PC 28 at Stevenage libra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96455</th>\n",
       "      <td>\":: I don't really want to deal with an amoeba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105991</th>\n",
       "      <td>AVRUCH you truly do show your colours.....this...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26586</th>\n",
       "      <td>\"\\n Nissim Cahn vandals \\n\\nI've blocked them ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4245 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  toxic  \\\n",
       "58787   Fuck, Shit, Damn, Cock, Pissant, Motherfucker,...      1   \n",
       "415     Thank you for your RACIST experimenting with t...      1   \n",
       "71909   Don't be a Dick\\nYou know what you did, don't ...      1   \n",
       "78991   STOP CHANGON IT \\n\\nOR I AM TWIST OFF YOURE LI...      1   \n",
       "45237   \"\\n\\n Nonexistent Image in \"\"Name\"\" \\n\\nThe im...      0   \n",
       "...                                                   ...    ...   \n",
       "128843  WHY DID YOU EDIT THE ARTICLE ON KURDISTAN? \\n\\...      1   \n",
       "150971  \"\\nAww thanks -) from PC 28 at Stevenage libra...      0   \n",
       "96455   \":: I don't really want to deal with an amoeba...      1   \n",
       "105991  AVRUCH you truly do show your colours.....this...      1   \n",
       "26586   \"\\n Nissim Cahn vandals \\n\\nI've blocked them ...      1   \n",
       "\n",
       "        severe_toxic  obscene  threat  insult  identity_hate  \n",
       "58787              1        1       0       1              0  \n",
       "415                0        1       0       1              0  \n",
       "71909              0        1       0       1              0  \n",
       "78991              0        1       0       1              0  \n",
       "45237              0        0       0       0              0  \n",
       "...              ...      ...     ...     ...            ...  \n",
       "128843             0        0       0       0              0  \n",
       "150971             0        0       0       0              0  \n",
       "96455              0        0       0       0              0  \n",
       "105991             0        0       0       0              0  \n",
       "26586              0        0       0       0              0  \n",
       "\n",
       "[4245 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87d81d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start to change the test part too into dataframe \n",
    "test_x = x_test.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f19090d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then concat the test src and target for the testing \n",
    "test_data = pd.concat([test_x , y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58382113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59210</th>\n",
       "      <td>User Jkelly is incapable of behaving responsib...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>Ashwamedha requires a master of ceremony (yaja...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111073</th>\n",
       "      <td>Are you complaining about the page stating him...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149208</th>\n",
       "      <td>into a Jewish family</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66151</th>\n",
       "      <td>\"\\n\\nThe piece of classical strings music that...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  toxic  \\\n",
       "59210   User Jkelly is incapable of behaving responsib...      1   \n",
       "7668    Ashwamedha requires a master of ceremony (yaja...      1   \n",
       "111073  Are you complaining about the page stating him...      1   \n",
       "149208                               into a Jewish family      0   \n",
       "66151   \"\\n\\nThe piece of classical strings music that...      0   \n",
       "\n",
       "        severe_toxic  obscene  threat  insult  identity_hate  \n",
       "59210              0        0       0       1              0  \n",
       "7668               0        0       0       0              0  \n",
       "111073             0        0       0       1              0  \n",
       "149208             0        0       0       0              0  \n",
       "66151              0        0       0       0              0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d2a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(dataset, vocab, tokenizer):\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    data = []\n",
    "    for item in dataset:\n",
    "            data.append(torch.tensor(vocab(tokenizer(item)), dtype=torch.long))\n",
    "        \n",
    "    if len(data) == 0:\n",
    "        return torch.tensor([0.,3.])\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "def pad(text):\n",
    "    if text.shape[0] > 300:\n",
    "        return text\n",
    "    padding = torch.zeros(300 - text.shape[0])\n",
    "    return torch.cat((text, padding))\n",
    "\n",
    "\n",
    "class Customtrain(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe.reset_index()\n",
    "        # preprocessing\n",
    "        self.data[\"comment_text\"] = self.data[\"comment_text\"].apply(cleaning_1st_step)\n",
    "        \n",
    "        ########\n",
    "        self.tokenizer = get_tokenizer('basic_english')\n",
    "        self.vocab = build_vocab_from_iterator(map(self.tokenizer, self.data['comment_text']), specials=['<unk>'])\n",
    "        self.vocab.set_default_index(self.vocab['<unk>'])\n",
    "      \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data['comment_text'].iloc[idx] \n",
    "        text = data_process(text, self.vocab, self.tokenizer).long() # Start to tokenize \n",
    "        \n",
    "        text = pad(text) # Padding\n",
    "       \n",
    "        if text.shape[0] > 300:    \n",
    "            text = text[ :300]\n",
    "            \n",
    "        #text = text.view(1,-1)\n",
    "        label = self.data.iloc[idx, 2:8]\n",
    "        label= torch.tensor(label)\n",
    "        return text , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95052c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "severe_toxic     0\n",
       "obscene          1\n",
       "threat           0\n",
       "insult           1\n",
       "identity_hate    0\n",
       "Name: 71909, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[2,2:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67c45e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58787</th>\n",
       "      <td>Fuck, Shit, Damn, Cock, Pissant, Motherfucker,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Thank you for your RACIST experimenting with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71909</th>\n",
       "      <td>Don't be a Dick\\nYou know what you did, don't ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78991</th>\n",
       "      <td>STOP CHANGON IT \\n\\nOR I AM TWIST OFF YOURE LI...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45237</th>\n",
       "      <td>\"\\n\\n Nonexistent Image in \"\"Name\"\" \\n\\nThe im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159281</th>\n",
       "      <td>LoL!! \\n\\nyou're GAY!! you will never know how...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36593</th>\n",
       "      <td>User:NHRHS2010 is a homo like mitt romney is. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83419</th>\n",
       "      <td>So in other words, WP is so riddled with troll...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46934</th>\n",
       "      <td>Well, user Burgass has done it again. Just loo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47631</th>\n",
       "      <td>Fuck you. I'll just make another account. You'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12094</th>\n",
       "      <td>Thanks! \\n\\nHey, thanks so much for fixing the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12011</th>\n",
       "      <td>u smell \\n\\nlikw dog poo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127966</th>\n",
       "      <td>Lots of Mormons in the edit crowd, I think, th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110964</th>\n",
       "      <td>THEY SHOULD DIE\\nAND PLEASE NOTE TOO THAT\\nbus...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11941</th>\n",
       "      <td>Liar \\n\\nThe Byzantium entry ıs a fraud.  That...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143970</th>\n",
       "      <td>sitush i know better than u who jatt sikhs are...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35564</th>\n",
       "      <td>kindness\\n\\nWow, your compassion sure disapper...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126409</th>\n",
       "      <td>F*CK YOU \\n\\nYou moth*rfucker, if you want me ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130441</th>\n",
       "      <td>The National Fat Cunt Prevention Board \\n\\nMy ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26708</th>\n",
       "      <td>To confirm!! I never asked you for help. I hav...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  toxic  \\\n",
       "58787   Fuck, Shit, Damn, Cock, Pissant, Motherfucker,...      1   \n",
       "415     Thank you for your RACIST experimenting with t...      1   \n",
       "71909   Don't be a Dick\\nYou know what you did, don't ...      1   \n",
       "78991   STOP CHANGON IT \\n\\nOR I AM TWIST OFF YOURE LI...      1   \n",
       "45237   \"\\n\\n Nonexistent Image in \"\"Name\"\" \\n\\nThe im...      0   \n",
       "159281  LoL!! \\n\\nyou're GAY!! you will never know how...      1   \n",
       "36593   User:NHRHS2010 is a homo like mitt romney is. ...      1   \n",
       "83419   So in other words, WP is so riddled with troll...      1   \n",
       "46934   Well, user Burgass has done it again. Just loo...      0   \n",
       "47631   Fuck you. I'll just make another account. You'...      1   \n",
       "12094   Thanks! \\n\\nHey, thanks so much for fixing the...      0   \n",
       "12011                            u smell \\n\\nlikw dog poo      1   \n",
       "127966  Lots of Mormons in the edit crowd, I think, th...      1   \n",
       "110964  THEY SHOULD DIE\\nAND PLEASE NOTE TOO THAT\\nbus...      1   \n",
       "11941   Liar \\n\\nThe Byzantium entry ıs a fraud.  That...      1   \n",
       "143970  sitush i know better than u who jatt sikhs are...      0   \n",
       "35564   kindness\\n\\nWow, your compassion sure disapper...      1   \n",
       "126409  F*CK YOU \\n\\nYou moth*rfucker, if you want me ...      1   \n",
       "130441  The National Fat Cunt Prevention Board \\n\\nMy ...      1   \n",
       "26708   To confirm!! I never asked you for help. I hav...      1   \n",
       "\n",
       "        severe_toxic  obscene  threat  insult  identity_hate  \n",
       "58787              1        1       0       1              0  \n",
       "415                0        1       0       1              0  \n",
       "71909              0        1       0       1              0  \n",
       "78991              0        1       0       1              0  \n",
       "45237              0        0       0       0              0  \n",
       "159281             1        1       0       1              1  \n",
       "36593              0        0       0       0              0  \n",
       "83419              0        0       0       0              0  \n",
       "46934              0        0       0       0              0  \n",
       "47631              1        1       0       1              0  \n",
       "12094              0        0       0       0              0  \n",
       "12011              0        0       0       1              0  \n",
       "127966             0        0       0       0              0  \n",
       "110964             1        0       0       0              0  \n",
       "11941              0        0       0       0              0  \n",
       "143970             0        0       0       1              0  \n",
       "35564              0        0       0       0              0  \n",
       "126409             1        1       0       1              0  \n",
       "130441             0        1       0       1              0  \n",
       "26708              0        1       0       1              0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a5686b",
   "metadata": {},
   "source": [
    "### Do Data custimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79293442",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data =Customtrain(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0577fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data =Customtrain(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f6f7e",
   "metadata": {},
   "source": [
    "## Start to dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84cebe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a3b866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(testing_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425bccb1",
   "metadata": {},
   "source": [
    "## Set the inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd155d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 136951  # Vocabulary size\n",
    "d_model = 512  # Embedding dimension\n",
    "nhead = 8  # Number of attention heads\n",
    "num_layers = 6  # Number of encoder layers\n",
    "d_ff = 2048  # Feedforward dimension\n",
    "max_seq_length = 300  # Maximum sequence length\n",
    "num_classes = 6 # Number of classes for classification\n",
    "dropout = 0.1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7373c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(vocab_size,num_classes, d_model, nhead, num_layers,d_ff, max_seq_length, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a732be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Adam optimizer with learning rate \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08b15acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion =  nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a3d5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "def train_model(model, train_dataloader , optimizer, device, num_epochs):\n",
    "    device=torch.device('cuda')\n",
    "    model=model.to(device)\n",
    "    # Loop through the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        # Initialize total loss for the current epoch\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    " \n",
    "        # Loop through the batches in the training data\n",
    "        for text , label in tqdm.tqdm(train_dataloader) :\n",
    "            # There is some record give error so ignore it by try and except \n",
    "            try:\n",
    "                text= text.long().to(device)\n",
    "                label= label.long().to(device)\n",
    "                optimizer.zero_grad() # Call the optimizer\n",
    "            \n",
    "            \n",
    "        # Start to train the model and see the predictions and then update the loss and the learning rate in the optimizer\n",
    "                outputs = model(text, label) \n",
    "                loss =criterion(outputs, label.long())  \n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == label).sum().item()\n",
    "                total_predictions += label.size(0)\n",
    "                loss.backward() \n",
    "                optimizer.step()\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba9f25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import cuda\n",
    "#device = cuda.select_device(0)\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0027459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all the cashes \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4dcfae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:3431'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ac99e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4245/4245 [01:35<00:00, 44.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4245/4245 [01:37<00:00, 43.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4245/4245 [01:38<00:00, 43.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4245/4245 [01:38<00:00, 43.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4245/4245 [01:38<00:00, 43.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Start the Tarining\n",
    "train_model(model, train_dataloader, optimizer, 'cuda', num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42cb85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "def test_model(model, test_dataloader , device, num_epochs):\n",
    "    device=torch.device('cuda')\n",
    "    model=model.to(device)\n",
    "    # Loop through the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        # Initialize 2 varubles\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    " \n",
    "        # Loop through the batches in the training data\n",
    "        for text , label in tqdm.tqdm(test_dataloader) :\n",
    "            try:\n",
    "                text= text.long().to(device)\n",
    "                label= label.long().to(device)\n",
    "                \n",
    "                outputs = model(text, label)\n",
    "                output.squeeze(1) # use it to squeeze the dim\n",
    "                for text , label in zip(output, label):\n",
    "                    correct_predictions +=1 \n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "    # Return the accurcy ratio \n",
    "    return correct_predictions/(len(test_loader)*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef6ad2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 16980/16980 [06:35<00:00, 42.90it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MEGAST~1\\AppData\\Local\\Temp/ipykernel_6828/1025441962.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Start the test and Get the accurcy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccurcy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cuda'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\MEGAST~1\\AppData\\Local\\Temp/ipykernel_6828/818899445.py\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(model, test_dataloader, device, num_epochs)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Return the accurcy ratio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcorrect_predictions\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Start the test and Get the accurcy \n",
    "accurcy=test_model(model, test_dataloader, 'cuda', num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aafdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the accury ratio\n",
    "print(accurcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b7064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c3c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
